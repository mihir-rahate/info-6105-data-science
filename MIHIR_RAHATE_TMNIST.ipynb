{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2830968,
          "sourceType": "datasetVersion",
          "datasetId": 1564532
        }
      ],
      "dockerImageVersionId": 30615,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'tmnist-alphabet-94-characters:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1564532%2F2830968%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240410%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240410T012622Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D891e1193a214ea3f49394ca7d8859654db09ee4255247de1f30bc28b509c9d8adebd0c9a1610f47a9b002f0ce767f73161ef18ff09d77469091b387a0844640deab61b9dcf4760428c981cca4d2afe5cc6734f70498a7c3d6b5ff513634d0085f4f5f8cbc13cbd83d870b81428bca1ad81169a194e6abde866e71c731a971e886b40d83d8d4d55b72a660d9bc3378c67df68c8b48cf500ccc023d0fef4fd2ea299545aa9397ef8b8bb79695b75c6b2f8ee3c3995052d9bd9174039de72a51157fc63f1cfb2c1ad15ee00426387468d0c83771251245cff8811b601f8462bf52060db3cd605e5bf31a42378657272d7a3c1bf385bd910a0afe02c23ceb6e4e981'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "VKu3XAKMnP4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71633e4a-b907-4d0e-98d2-b26d1d3c574d"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tmnist-alphabet-94-characters, 88850214 bytes compressed\n",
            "[==================================================] 88850214 bytes downloaded\n",
            "Downloaded and uncompressed: tmnist-alphabet-94-characters\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/Mihir-DRIVE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IpCH_Kpo16N",
        "outputId": "754f6cb4-d8c3-4982-e42d-494d90d4862f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /Mihir-DRIVE; to attempt to forcibly remount, call drive.mount(\"/Mihir-DRIVE\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network Type Classification**"
      ],
      "metadata": {
        "id": "YLx26nrSLQeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ],
      "metadata": {
        "id": "Un1mTjleLXpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A benchmark dataset of handwritten Thai numerals, the TMNIST dataset is frequently used in machine learning for image classification applications. It is composed of 10,000 test images and 60,000 training images, each measuring 28 by 28 pixels and depicting a handwritten Thai numeral from 0 to 9. The MNIST dataset, a comparable dataset of handwritten English digits, served as the model for the creation of this new dataset. The introduction of the Tmnist dataset aims to facilitate the development of machine learning algorithms for the recognition of handwritten Thai numerals, a crucial task for numerous applications in Thailand, by researchers and practitioners.\n",
        "The dataset aims to advance the development of image classification models for Thai characters and is freely accessible for academic and commercial use.\n"
      ],
      "metadata": {
        "id": "s1Fb9T1RLbgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing necessary libraries**"
      ],
      "metadata": {
        "id": "gu1Tp6SILevx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey there! Welcome to the world of neural networks and the TMNIST dataset. Imagine you're a chef and you've got lots of ingredients to make the perfect dish – that's sort of what we're doing here with our code.\n",
        "\n",
        "1. **Numpy & Pandas**: Think of `numpy` and `pandas` as your prep tools. They help us chop and prepare our data – numbers, lists, tables – so that everything is ready for cooking (or in our case, for the neural network to learn from).\n",
        "\n",
        "2. **Scikit-learn**: Now we've got some special gadgets from `scikit-learn`. They're like our measuring cups (`train_test_split`) to divide our data into portions – some for learning (training) and some for testing how well we've learned. We've also got a great shuffling tool (`shuffle`) to mix things up and a label maker (`LabelBinarizer`) to keep our data labels neat and organized. Lastly, we have a taste-test tool (`accuracy_score`) to see how yummy our neural network's predictions are.\n",
        "\n",
        "3. **TensorFlow & Keras**: This is the main event – `tensorflow` and `keras`. They're like our high-tech oven and mixers. With them, we can build our neural network layer by layer – some layers are for mixing (`Dense`), some for baking (`Conv2D`), and some for adding texture (`Dropout`). And just like you don't want to overbake your cake, `EarlyStopping` is like our kitchen timer that stops the training before our model gets overcooked.\n",
        "\n",
        "4. **Matplotlib**: After all the cooking, we want to present our dish beautifully, right? `matplotlib` is our plating kit. It helps us make pretty graphs to show off our results.\n",
        "\n",
        "5. **Warnings and Inline Plotting**: Nobody likes a messy kitchen, so we tell our code to ignore any little warnings that pop up – like a spill that's not too important to clean up right now (`warnings.filterwarnings('ignore')`). And we set up our kitchen to show us the food as we plate it, right on the counter (`%matplotlib inline`).\n",
        "\n",
        "Now, with all these tools and ingredients ready, we're set to make some amazing neural network recipes with the TMNIST dataset! Let's get cooking! 🌟👩‍🍳👨‍🍳"
      ],
      "metadata": {
        "id": "RTZPH08gtvVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries for data handling\n",
        "import numpy as np  # For numerical and algebraic operations\n",
        "import pandas as pd  # For reading and manipulating datasets, especially from CSV files\n",
        "\n",
        "# Preprocessing and utilities from scikit-learn\n",
        "from sklearn.model_selection import train_test_split  # To split the dataset into training and test sets\n",
        "from sklearn.utils import shuffle  # To shuffle the data and ensure it's randomly ordered\n",
        "from sklearn.preprocessing import LabelBinarizer  # For converting labels into a one-hot encoded format\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score  # For evaluating the performance of our model\n",
        "\n",
        "# Deep learning framework\n",
        "import tensorflow as tf  # The main framework for building and training neural networks\n",
        "from tensorflow.keras.models import Sequential  # To create a linear stack of neural network layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, SimpleRNN  # Different types of layers we can add to our model\n",
        "from tensorflow.keras.utils import to_categorical  # For one-hot encoding of labels\n",
        "from tensorflow.keras.callbacks import EarlyStopping  # To stop training early if the model isn't improving\n",
        "\n",
        "# Visualization and warning management\n",
        "import matplotlib.pyplot as plt  # For plotting graphs and visualizing data\n",
        "import warnings  # To handle warnings that might clutter the notebook\n",
        "\n",
        "# Setup inline plotting and suppress warnings for a cleaner notebook\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "jEcmsuVx9H4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyzing the dataset**\n",
        "It starts by loading a CSV file into a pandas DataFrame, which is a table-like data structure that allows for convenient data manipulation in Python. The file '94_character_TMNIST.csv' seems to contain a column named 'labels' where different characters are stored.\n",
        "\n",
        "Once the DataFrame is ready, the first few rows are displayed using df.head(), which is a quick way to peek at the dataset. The shape of the DataFrame, meaning the number of rows and columns, is also printed out using df.shape to understand the size of the data we are dealing with.\n",
        "\n",
        "Next, the code extracts all the unique characters present in the 'labels' column to analyze the composition of the dataset. It classifies these characters into four categories: uppercase letters, lowercase letters, digits, and special symbols. This classification is done using regular expressions, which are patterns used to match character combinations in strings. For each category, the code compiles a regular expression that matches the relevant set of characters.\n",
        "\n",
        "The matching characters are found using the findall method of the compiled regular expressions and stored in lists (or a set, in the case of symbols). The code takes care to discard an underscore character from the set of symbols, likely because it wants to treat it as not significant for the groups being considered.\n",
        "\n",
        "Finally, the DataFrame is updated with a new column named 'group', which labels each entry based on the category of character it belongs to. It does so by iterating over the groups of characters and assigning a group number to the corresponding rows in the DataFrame.\n",
        "\n",
        "In essence, this script is a data preprocessing step where the dataset is being enriched with categorical information, which can then be used for further analysis or machine learning tasks."
      ],
      "metadata": {
        "id": "mzj8Q3rY3p8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset into a pandas dataframe\n",
        "df = pd.read_csv('/Mihir-DRIVE/MyDrive/Dataset/94_character_TMNIST.csv')\n",
        "# Display the first few entries of the dataframe\n",
        "df.head()\n",
        "\n",
        "# Display the shape of the dataframe\n",
        "df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz0s9x9C2QNT",
        "outputId": "e978af22-be04-484f-ec10-4e2bd00842d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(274093, 786)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n"
      ],
      "metadata": {
        "id": "zmDChj1Y3ESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting unique labels from the dataframe\n",
        "unique_labels = list(df['labels'].unique())\n",
        "\n",
        "# Regular expression patterns for checking different types of characters\n",
        "regex_uc = re.compile(r\"[A-Z]\")  # uppercase\n",
        "regex_lc = re.compile(r\"[a-z]\")  # lowercase\n",
        "regex_numbers = re.compile(r\"[0-9]\")  # digits\n",
        "regex_symbols = re.compile(r\"[\\W]|[\\_\\,]\")  # special symbols\n",
        "\n",
        "# Extracting characters based on the regex patterns\n",
        "lower_case_chars = regex_lc.findall(str(unique_labels))\n",
        "upper_case_chars = regex_uc.findall(str(unique_labels))\n",
        "number_chars = regex_numbers.findall(str(unique_labels))\n",
        "symbol_chars = set(regex_symbols.findall(str(unique_labels)))\n",
        "symbol_chars.discard('_')  # removing unwanted character from set\n",
        "\n",
        "# Grouping the labels based on the extracted characters\n",
        "groups = {'lowercase': lower_case_chars, 'uppercase': upper_case_chars,\n",
        "          'numbers': number_chars, 'symbols': list(symbol_chars)}\n",
        "for i, (group_name, char_list) in enumerate(groups.items(), start=1):\n",
        "    df.loc[df['labels'].isin(char_list), 'group'] = str(i)"
      ],
      "metadata": {
        "id": "t7V9tu-e17Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`X` will be the features and `y` will be the target variables.\n",
        "\n",
        "1. `X` is assigned the values from all rows and all columns except the first two and the last one, converting the data type to 'float32'. This implies that the first two columns are likely to be non-feature data (like IDs or labels) and the last column might be the target variable.\n",
        "\n",
        "2. `y` is created as a DataFrame containing only the 'labels' column.\n",
        "\n",
        "3. Unique labels are extracted from `y` and assigned to `labels`.\n",
        "\n",
        "4. A list of numerical values ranging from 0 to the number of unique labels minus one is created as `values`.\n",
        "\n",
        "5. A dictionary called `label_dict` is created to map the original textual labels to these numerical values.\n",
        "\n",
        "6. An inverse dictionary, `label_dict_inv`, is also created for the opposite mapping (from numerical values back to textual labels).\n",
        "\n",
        "7. The 'labels' column in `y` is then updated to the numerical values using the `label_dict`.\n",
        "\n",
        "8. The content of `label_dict` is printed out to verify the mappings.\n"
      ],
      "metadata": {
        "id": "LiOzoMZ55ZdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation for model training\n",
        "# Selecting feature columns and converting the data type to float32\n",
        "X = df.iloc[:, 2:-1].astype('float32')\n",
        "\n",
        "# Target variable setup\n",
        "y = df[['labels']].copy()  # Create a copy to avoid modifying the original DataFrame\n",
        "\n",
        "# Generate a mapping from unique labels to integers\n",
        "labels = y['labels'].unique()\n",
        "values = list(range(len(labels)))\n",
        "label_dict = dict(zip(labels, values))\n",
        "label_dict_inv = {v: k for k, v in label_dict.items()}  # Inverse mapping\n",
        "\n",
        "# Apply the mapping to the 'labels' column to convert labels to integers\n",
        "y['labels'] = y['labels'].map(label_dict)\n",
        "\n",
        "# Print the mapping dictionary\n",
        "print(label_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgT8tDXN1698",
        "outputId": "438ab5b5-3a55-4172-9429-1e24c8ad18cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'6': 0, 'D': 1, 'f': 2, '/': 3, 'F': 4, 'x': 5, 'J': 6, '8': 7, 'H': 8, 'k': 9, '@': 10, '1': 11, '=': 12, 'g': 13, ')': 14, '2': 15, 'd': 16, '^': 17, '3': 18, 't': 19, '#': 20, '.': 21, '4': 22, 'o': 23, '\"': 24, 'y': 25, 'A': 26, 'u': 27, 'G': 28, '-': 29, 'm': 30, 'W': 31, '&': 32, 'c': 33, '9': 34, 'N': 35, ']': 36, 'P': 37, 'X': 38, '|': 39, '}': 40, 'h': 41, '7': 42, 'j': 43, '5': 44, '>': 45, '?': 46, 'b': 47, '*': 48, 'w': 49, 'l': 50, '0': 51, '$': 52, 'I': 53, 'Y': 54, '%': 55, ':': 56, 'T': 57, 'K': 58, 'E': 59, '<': 60, 'V': 61, '{': 62, 'M': 63, 'S': 64, 'a': 65, 'i': 66, 'r': 67, \"'\": 68, 'p': 69, ';': 70, '[': 71, '+': 72, 'e': 73, 'U': 74, '(': 75, 's': 76, '~': 77, ',': 78, 'C': 79, 'q': 80, '_': 81, 'n': 82, 'B': 83, 'z': 84, 'v': 85, 'O': 86, 'R': 87, '`': 88, 'Z': 89, 'Q': 90, 'L': 91, '!': 92, '\\\\': 93}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training:**\n",
        "Training and Test sets\n",
        "\n",
        "\n",
        "1. It splits the feature matrix `X` and the target vector `y` into training and testing sets, with an 80-20 split. This means 80% of the data is used for training the model, and the remaining 20% is reserved for testing its performance.\n",
        "\n",
        "2. It prepares the inputs for neural network training. The training and testing feature sets are reshaped to the size of 28x28, which is the typical size for each image in datasets like MNIST, suggesting that each row in `X` represents a flattened image.\n",
        "\n",
        "3. It converts the target vectors (`y_train_alt` and `y_test_alt`) into one-hot encoded matrices using the `to_categorical` function. One-hot encoding is necessary for categorical targets in classification tasks.\n",
        "\n",
        "4. Finally, it prints out the shapes of the prepared training and testing sets for both the features and the targets.\n"
      ],
      "metadata": {
        "id": "PIxTh6CBLlh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required function from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train_alt, X_test_alt, y_train_alt, y_test_alt = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Defining image dimensions\n",
        "Length, Height = 28, 28\n",
        "# Determining the number of unique classes for target categorization\n",
        "NCl = y_train_alt.nunique()[0]\n",
        "\n",
        "# Reshaping the input data to fit the expected input of a 2D convolution layer\n",
        "# The reshape assumes one channel (grayscale images). For RGB images, reshape would need an additional dimension.\n",
        "X_train_alt = X_train_alt.values.reshape((-1, Length, Height, 1))  # -1 infers the number of samples\n",
        "X_test_alt = X_test_alt.values.reshape((-1, Length, Height, 1))\n",
        "\n",
        "# One-hot encoding the target variable to prepare for neural network output layer\n",
        "y_train_alt = to_categorical(y_train_alt['labels'], num_classes=NCl)\n",
        "y_test_alt = to_categorical(y_test_alt['labels'], num_classes=NCl)\n",
        "\n",
        "# Printing out the shapes of the processed training and testing data\n",
        "print(f'X: Train, Test data shapes: {X_train_alt.shape}, {X_test_alt.shape}')\n",
        "print(f'Y: Train, Test data shapes: {y_train_alt.shape}, {y_test_alt.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEftas5Y6sIg",
        "outputId": "b062ae95-a00d-4318-811d-854dc531c313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: Train, Test data shapes: (219274, 28, 28, 1), (54819, 28, 28, 1)\n",
            "Y: Train, Test data shapes: (219274, 94), (54819, 94)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT NEURAL NETWORKS LIBRARY**"
      ],
      "metadata": {
        "id": "pq121ChI7NRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing a subset of the character images from the training dataset. It starts by shuffling the first 500 training examples and then selects 12 of these to display in a 3x4 grid of subplots. Each image is reshaped to 28x28 pixels for display purposes and then reshaped again to (1,28,28,1) to potentially prepare for input into a convolutional neural network model, though the prediction part isn't explicitly shown in the snippet. Additionally, it includes imports for building a neural network model with TensorFlow and Keras, and it ends by checking the shape of `X_train_alt` and printing `X_test_alt`.\n",
        "\n"
      ],
      "metadata": {
        "id": "7dxUERI97c9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary imports for data visualization and model creation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "R6Z774Rd6sDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Shuffling a subset (first 500 samples) of the training data\n",
        "random_subset = shuffle(X_train_alt[:500], random_state=0)  # Added a random state for reproducibility\n",
        "\n",
        "# Displaying 12 characters from the dataset in a 3x4 grid\n",
        "fig, ax = plt.subplots(3, 4, figsize=(10, 10))\n",
        "axes = ax.flatten()\n",
        "for i in range(12):\n",
        "    # Reshape to 28x28 for displaying the image\n",
        "    img = np.reshape(random_subset[i], (28, 28))\n",
        "    axes[i].imshow(img, cmap=\"Greys\")\n",
        "    # Note: The reshaping for model prediction isn't used here, so it's omitted\n",
        "    axes[i].axis('off')  # Turn off the grid for a cleaner look\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "pVPfVa8V7jgI",
        "outputId": "95797218-930f-4c6e-869a-05b3759f9f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 12 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAANlCAYAAABhV5qeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+o0lEQVR4nO3daZSdZZk27KdSYypzSAiEQEJICHMCQiM0MqhMQtMqYkdwYKEsFVEcsdXXdgCXSxqbtRocGnQ1ghMiaAsBgQZEQIgIRCYBIQkJmQmZx0pVfT/e9X79vXx63TvuuqoqleP4ez713FelqvbeZ54fV0N3d3d3BQAAAPS4QX09AAAAAAxUSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkTX09AAAAf93SpUvD/Oyzzy7e4ze/+U2Y/8M//EOY/9d//VfxDBgotm7dGuYvvfRS8R533XVXmN99991h/uijjxbPeOWVV8K8q6srzCdMmBDmZ5xxRnGGM888M8wPPfTQMG9rayueMRB40g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRp6O7u7u7rIQD6UmdnZ/GauXPnhvm1114b5j/+8Y/DfP78+cUZ6tXc3Fy8ZvTo0WF+wQUX1PX1f/zjH4sz/OhHPwrzCy+8MMzf//73F8+YNm1a8RroLz7wgQ+Eeelvoqqqavr06WHe0NCwXTNBX6mlupSuWb58eZg//fTTYX7//fcXZyidUdoFPnTo0OIZpc8va9euDfNnn302zMeOHVuc4aCDDgrzs846K8ynTp1aPGP48OHFa/o7T7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkaerrAQai7u7uML/kkkvCfOnSpWF+xRVXFGdobW0N846OjjC/9tpri2d873vfC/Onn346zJubm8P8+OOPL87whS98IcwPP/zw4j0Y+DZs2BDmzz77bPEepb+J++67L8w3btwY5vvss09xhqlTp4Z56e9+1apVxTNefPHFML/tttvCvKkpfltZvnx5cYatW7fWdY/Vq1cXz4Adyd133x3m3/72t4v3aGho6KlxoE91dXUVrym97z/44INhft1114X5nDlzijPMmDEjzI899tgwP+6444pntLe3h3np/fIHP/hBmJc+21RVVT3yyCNh3tnZGebvfe97i2cceOCBYT5oUP9/jtz/JwQAAIAdlNINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAk9nRvp9KuuaqqqosuuijMv/Wtb9U1w5IlS4rXXH/99WFe2oH96KOPbs9IKX75y1/Wfc2NN94Y5u94xzu2YyL6qy1btoT53Llzw7y0c76qqurnP/95mI8ePTrM3/KWt4T5EUccUZxh0qRJYd7c3Bzmr776avGM5557LsyfeOKJMP/DH/4Q5gsXLizOUNrBun79+jAv7USHHc3KlSvDfEfYUQu16u7uDvPSDu6qqqof/vCHYX777beH+fPPPx/mb33rW4szlK6ZPn16mLe1tRXPaGhoCPMJEyaE+ahRo8J88ODBxRm+//3vh3nps/i0adOKZ0yePDnMhwwZUrxHX/MqDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJLGnezu98sorxWtKuwHrVcv+6gMPPDDMFyxYEOalvX9VVVXDhw8P8zVr1hTvke2cc84J85NPPrl4j2HDhvXUOCQp7bD99a9/HebXXHNN8YyRI0eGeWnn+7nnnhvmU6dOLc5Qr9Lu06oq78gu7eEu7ev80Y9+VJxh06ZNYV7aSWxnMcCOa926dWH+1FNPFe9x5513hnlpD3dpL3Qte7pnzJgR5qUd2T2htbU1zEufPQ444IDiGaXPyYsXLw7z0s+ilnv0xmeoevlkAgAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIElTXw+woxk3blzxmo9//ONh/pWvfKWHpvnrSkvkf/zjH4f5mWeeWTyjpaUlzJcuXRrmp556apjPmTOnOEPJ1q1bw3zWrFnFe8ycObPuOcj129/+NsxvuummMG9rayuecf7554f5e97znjCfNGlS8YxsDQ0NxWsGDYr/L/bQQw8N83POOSfMFy5cWJzhnnvuCfPBgweHeWtra/EMAPpGd3d3mL/00kthXnpPr6qqeuihh8J8zz33DPNjjjkmzF/3utcVZxg+fHjxmmyl9/T29vYwr+WzS+nf8rnnngvzJUuWFM94+umnw3zq1KnFe/Q1T7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAk9nQnGD16dF+PUP3iF78I89NPPz19ht122y3Mr7322jCfMWNGzw3zV9SyC9ye7r61evXq4jWPP/54mM+bNy/MJ06cWDyjtLt+r732CvPm5ubiGf1BaZd3S0tLmJf2ko4cObI4Q2mv6LBhw8K8tMcbgL6zefPmMH/iiSfC/LbbbiuesXbt2jA/4ogjwvyMM84I89bW1uIMA8GQIUOK14wbNy7MX3jhhTDftGlT8YwVK1YUr+nvPOkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACS2NOdoJbdz/Uo7b+uqqo67bTTUmfoCVOmTOnrEaqOjo6+HoGCF198sXjNggULwryxsTHMX//61xfPmDx5cpjbDf2/lf6tS3u+q6q8K3zEiBFh3t7eXjwDgL6xaNGiMH/qqafC/KWXXiqeUXofmDZtWpjvvffeYd7UtHNUqNJ7elWVd5aX3tO3bdtWPKO0231H4Ek3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQZOdYMtfLHn744dT7H3PMMcVrSjvx+oP+sCN73LhxfT0CBY8//njxmmXLloX5+PHjw/zoo48unlHaL70j/M31hkGD4v/LbW5urvuMUaNGhfmQIUPqPgN6U+n9cP369WFeyy5d6C8eeOCBMJ87d27dZ0ycODHMp0yZEuZDhw6te4aBoKurq3jN1q1b6zqjltevgfAa50k3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJE19PcCOpqOjo3jNc889lzrD9OnTU+/fW+bPn9/XIwyYf8uBbOHChcVr1q5dG+YjRowI83322ad4RmNjY/Eayv9Ora2txXs0NDSE+ZgxY8J8yJAhxTOgt9TyXvf2t789zH/4wx+GeelvBvqTOXPmhPmCBQvCvK2trXjGwQcfHOZjx44t3oOqWrduXfGapUuXhvm2bdvCvJaf50D4eXnSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJLGnezstXry4eE1XV1fqDDNmzEi9f2+ZNWtWX49gT/cOYMOGDcVrtm7dGual3dEtLS3FM+zBrU13d3eYd3R01H2P4cOHh3ktP0/oT0r76zdt2tRLk0C+efPmhfmKFSvCvJbX+AkTJoR56X1koCi9n3Z2dob5ypUri2eU9nSX3vdHjhxZPGPixInFa/o7T7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAk9nRvp+eff76vR6geffTR4jWnn356L0wSW79+fZh/85vfTJ/hoIMOCvPddtstfQbqU9qxXVVVNWhQ/P+H27ZtC/PSnu+qKu+63Fl0dXWF+erVq8N8/vz5xTNKe0ObmuK3LjvV6U8mTZpUvOaBBx4I89Lv/HnnnVc8w98F/cXixYvDfOPGjWFe+nuoqqoaPXp0mLe1tRXvMRCU3rO3bNkS5suWLSueUbqm9Plp1113LZ6x9957F6/p7zzpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkKS8XZ7/yx/+8Ie+HqG69NJLi9cceeSRYX7iiSeGeWNjY/GMFStWhPl73vOeMF+1alXxjHp94xvfSD+DXKNHjy5eM3jw4DDfuHFjmC9ZsqR4RldXV/GancHWrVvD/Nlnnw3zhx56qHhGR0dHXTP4WbGjKb3nDhs2LMw7OzuLZzQ1+chH/7Bt27YwL72G1/K73NLSEuaDBu0czx1L76d//vOfw/yFF14ontHc3BzmEydODPOpU6cWzxg+fHjxmv5u5/iNAwAAgD6gdAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIImljdtpzpw5fT1Ccb9hVVXVqaeeGualHYe17MN79dVXi9dke+tb3xrmp5xySu8MQpp99tmneM3IkSPDfP78+WE+d+7c4hm17MHdGZR2ej766KNhXtqZXlVV1d3dHebr168P89JeUgD6TltbW5iX9taX9nhXVfl9oJZ77AhK38fmzZvD/N577w3zP/3pT8UZhg0bFubHHXdcmE+bNq14Rmtra/Ga/s6TbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIIk93dvpwQcfTD/j+OOPD/NFixYV71HapVva9d0fdnCfeOKJxWt+/OMfh/mgQf5faUc3ffr04jXjxo0L89mzZ4f5Qw89VDzjvPPOC/OhQ4eGeX/4Xaxl13hpj/bNN98c5r/97W/DvJZdm6W9oq+88kqY17ILfMSIEcVrAOh548ePD/OVK1eG+bp164pnrFq1Ksy3bNlSvMeOoPR5vvTvcNddd4X5E088UZxh9913D/MzzzwzzPfee+/iGQNB338KBAAAgAFK6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBJ7ul9j06ZNYV7Ljux6nXLKKWH+sY99rHiPq666Ksyvu+66MH/hhReKZ7S1tYX5UUcdFeYf+tCHwvy0004rztDY2Fi8hh3bHnvsUbxm6tSpYd7e3h7mjz32WPGMp556KsyHDBkS5sOHDy+eUa/Svs7Vq1cX7/HAAw+E+d133x3mpV3gpdeFqqqq+++/P8wXLlwY5qUdr1VV3isKQI4jjjgizDdu3BjmDz74YPGMJ598MsyXL18e5tOmTQvzhoaG4gwl3d3dYd7V1VW8x/z588P85ptvDvM//elPYb7vvvsWZyj1lgMPPDDMS5+fBgpPugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRp6usB+psFCxb09QjV4YcfHuaDBw8u3uMzn/lMXTn0F+3t7cVrjjnmmDB/4oknwvy2224rnnHdddeFeenvcsaMGWHe2NhYnKG7uzvMV69eHeaPPPJI8YzPfe5zYd7Z2RnmJ510UpgfeOCBxRkeffTRMH/mmWfC/Mknnyyesffee4f5kCFDivcAYPudcMIJYb506dIw//3vf188Y86cOWFeep854IADwryWzyYNDQ1hvm3btjBfs2ZN8Yw777wzzG+99dYwL30fpZ9VVVXV2972tjAfO3ZsmLe2thbPGAg86QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJLY0/0aTz/9dF+PUE2dOrWvR4AdymGHHRbm//RP/xTmDz74YPGMWbNmhfm8efPCvDTjtGnTijMsX748zEuvX7Xs6V65cmWYf/GLXwzzk08+Ocw3bdpUnKGpKX5rKv28ajnjqaeeCvOvfe1rxXtAbyntje/q6uqlSaB+hxxySJgvWLAgzB944IHiGc8//3yY/+pXvwrzLVu2hPmJJ55YnKG0f7r0nn7TTTcVz5g9e3aYr1u3LszPPvvsMC/t4K6q8ueX5ubm4j12Bp50AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASezpfo1HH300/YyGhoYw32233dJngIGkvb09zI8++ugw//rXv1484/rrrw/zZ599NsxLe0d32WWX4gwbNmwI846OjjCfPHly8YyLLroozP/xH/8xzEuvX6U94FVVVQcffHCYl16nS7tPq6qqlixZUrwG+ovjjjsuzOfNm1e8R2mXLvSWtra2MD/yyCPD/GMf+1jxjDvuuCPMFy9eHOZ33XVXmL/wwgvFGUqfTUpK7/lVVVXHH398mO+3335hfswxx4T5HnvsUZyhtI+c/82TbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEma+nqA/ubxxx9PP2PatGlh3tLSkj4DDCSNjY1hPmbMmDA/44wzimcMGzYszB955JEwX7x4cZhv2bKlOENra2uY77bbbmF+2GGHFc849thjw3zUqFFhXnr96u7uLs7wvve9L8wPOeSQMG9vby+eMWPGjOI10F9cfvnlYT5z5sziPWbPnh3mJ598cpjfeuutxTOgFg0NDWE+fvz4MD/99NOLZ2zYsCHM77jjjjC///77w/y3v/1tcYahQ4eG+Z577hnmpffjqqqqU089NcwPP/zwMC/NWPp8Re086QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJI0dNeyNHUnUtpBu3r16rrPOPfcc8P8P//zP+s+A+hdpZ2gpdeOdevWFc8YPnx4mI8cOTLMa9lfna2Wt5ytW7eG+apVq8K8lr2io0ePrvseAAC18KQbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABI0tTXA/S2NWvWhHlP7OEumT59evoZQO8aMmRIXfnOoqGhoXhNa2trmO+22249NQ4AQDpPugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCQN3d3d3X09BAAAAAxEnnQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACBJU18PAAAAMJDMnDkzzG+44Ya6zxgyZEiYr1+/vu4z6BmedAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEns6d5OK1euLF7z1a9+NcxvvPHGMC/t9bvooouKM+y+++5h3tQU/+gHDfL/MfD/1dXVFea/+93vwvzQQw8N89Kuzf7ilVdeCfOXX345zGfMmNGD0wDAwLTbbrsVrzn22GN7YRJ6gmYFAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgSVNfD7CjWbhwYfGap556KszXr18f5ldccUWYX3nllcUZ3vnOd4b5Bz/4wTA/6KCDimcMHz48zJua/HrRP3R0dIT5LbfcUrzHP//zP4f5n//857ryKVOmFGeo14IFC4rXXHrppWH+/e9/P8zf//73h/nVV19dnAEAdnannHJK8ZpSZ6D/8KQbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIYpHydpo+fXrxmp/+9KdhfsEFF4T5zTffHOadnZ3FGX7yk5+E+S9/+cswP+mkk4pnnHPOOWF+zDHHhPm4cePCvKGhoTgD1GLt2rVhfuqppxbv8clPfrKnxklTem0YOnRo8R6l17iurq7tmgkA2H5tbW09cg39gyfdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEnu6t1Mtu6N32WWXMC/t1Ovu7g7zKVOmFGd45zvfGeY33XRTmP/qV78qnnHnnXeG+WmnnRbmZ599dpi/+c1vLs5Qy95hKP1N1uLYY48N8+uvv77uM+rV2NgY5qNHjy7e44QTTuipcaBuV111VZh/9KMfTZ+h9He1ZMmSMB87dmzxjJdeeinMJ02aVLxHvdrb28N84cKFYV7L68vTTz8d5gcddFDxHvUaOXJkmJe+T5876C1dXV19PQI9yJNuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZr6eoCBaOPGjWG+ePHiMO/u7g7zE088sTjD5z//+TA/++yzw/znP/958Yxvf/vbYX7jjTeG+T333BPm73rXu4ozfOpTnwrziRMnhnlDQ0PxDKiqqmpra+vrEXpFS0tLX48A/683vvGNfT1C1dnZGeZPPvlkmNfyPey5555hPmhQ/Iykq6ureEZJ6bPL888/H+avf/3ri2fss88+2zVThtWrV4f5yy+/HOb77bdfD04D7Cw86QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJLY051g5cqVYb5q1aq67n/YYYcVr2lvbw/z/fffP8wvvvji4hlnnnlmmH/mM58J89tvvz3Mr7766uIMTzzxRJhfccUVYT5jxoziGaX9qADkGDt2bF+PUFR6v61F6X1mxIgRYV7v54pa9MTPorW1tQcmyTVmzJi+HgGqqvL5c6Dx0wQAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJLY051gyZIlYV7vPs3p06fX9fVVVVUNDQ1h3tbWVrzHAQccEOa33HJLmH/3u98N84suuqg4w/333x/mpV3id955Z/GMKVOmhHnp3xKAv013d3dfj1C01157pZ+xdu3a9DMGDx4c5j3xfXZ0dNR9j3rtscceYb7LLrv00iQQ6+rq6usR6EGedAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEns6U4wf/78MF+zZk1d9588eXJdX99TSvupGxsbw/xDH/pQmE+cOLE4w7nnnhvmpZ/FZz7zmeIZP/3pT8O8lp3m0NnZ2dcjwA5n48aNfT1C1dzcHObjxo2r+4zSHu7eeP2YOXNmmJf+HWqxcuXKuu9Rr3e/+91hXvpsA71l0CDPRgcSP00AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJmvp6gB1Nd3d38Zp58+aF+bp168J86NChYT5ixIjiDDuCxsbGMH/zm99cvMfnP//5MP/c5z4X5rfcckvxjMWLF4f55MmTi/dgx9fa2lrX1y9fvjzMp02bVtf9YSAqvf72hunTp4d56b2sFn/+85/rvke9PvjBD6af8eyzz6afUfLhD3+4r0eAmnR1dfX1CPQgT7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAk9nRvpy1bthSvWbJkSZhv27YtzA877LAw74mdoDuCtra24jVvfOMbw3zPPfcM8xdffLF4xrJly8Lcnu6dw957713X11933XVh/oY3vKGu+9eiltev733ve+lzQK1qeY3Oduihh6af8ctf/jL9jJJRo0aln3HTTTeln3HiiSeG+cSJE9NnAHgtT7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAk9nRvpw0bNhSvWb58eV1nvO51r6vr63cmgwbF/2/U3Nwc5u3t7cUz9tprr+2aiYFp5syZYf7pT386zEv7rzs7O4szlPbPlnYaz507t3jGhRdeGObf+MY3iveAnvL888/39Qh1vwd0dHQUr7nmmmvqOqMnbNmypa6v37x5c/Ga6667rq4zavHv//7v6WdAbyh9xmXH4qcJAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgSVNfD7CjWb16dfGahQsX1nXG4YcfXtfXDxRbtmwpXnP//feH+UsvvRTm5513XvGMMWPGFK9h4Bs/fnyYP/DAA2F+4YUXhvkNN9xQnOGZZ54J80984hNh/vnPf754xty5c4vXQG9ZunRpX49Qtbe31/X1N954Y/GaZcuW1XVGT6jl803kmmuuKV6zbt26us6o5T17v/32q+sM6C+6urr6egR6kCfdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEnu6t9Orr75avGbRokV1nXHwwQfX9fU7is7OzjD/xS9+UbzHV7/61TA/8cQTw7yWvcUtLS3Fa+Doo48O88cee6yXJoGBY+vWrX09QrVixYowL+22/+AHP9iT46R56qmnwnzMmDFh/ulPf7ruGSZOnBjmV155Zd1nwI5i0CDPRgcSP00AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJPd3baeXKlcVrlixZEualvXulPZX9RXd3d5hv3LgxzC+++OIwv/rqq4szvPOd7wzzK664Isx33XXX4hlA7RoaGvp6BAaQ3Xbbra9HqL7zne+E+eWXXx7m27Zt68lx0nzhC18I8zVr1oR5V1dX8YxRo0aF+b333hvm7e3txTNgoKjlb4odhyfdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEnu6X6OjoyPM586dW7zH1q1bw3zq1Klh3tzcXDyjXqXvc+3atcV73HrrrWH+L//yL2He1BT/+n39618vzvDhD384zIcMGVK8B/A/uru76/r6oUOH9tAkUFWnnXZamF922WXpM5T2U5fsuuuuxWtKu8DPPPPMumaoxapVq+r6+j333LN4zcMPPxzm48ePr2sGgP7Kk24AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJmvp6gP5m69atYT5//vy6z3jd614X5oMGxf8XsmXLluIZS5cuDfMHH3wwzP/jP/6jeMaSJUvC/C1veUuYf+QjHwnzAw44oDhD6d8K2D6l18CSyZMn99AkUFXHHHNMmJ9wwglhfu+999Y9w+DBg8P8ggsuCPMvf/nLxTOGDBkS5ieeeGKY33XXXcUzSkrf5yc+8Ykw/8IXvlA8o729fbtmgp2Zz7gDi58mAAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQxJ7u1yjtqH3ppZfqPmPkyJFhPnv27DD/3e9+VzzjjjvuCPPSHu+TTjqpeMYll1wS5kceeWSYt7a2Fs+A/mLFihVhvmzZsjA/6KCDenKcNKXvs+SUU07poUmgvKf2zjvvDPNFixYVz+ju7g7z8ePHh3lLS0vxjHrNmjUrzHvi+5wwYUKYNzc3F88Aes7mzZvrvqatra2nxqFOnnQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJ7Ol+jU2bNoX5iy++WPcZpR3av/71r8O8lp17M2fODPPTTz89zPfdd9/iGUOHDg3zhoaG4j1gR1HaXT9nzpww/9nPfhbmZ5111vaOlOK+++4L89Jrxz777NOT40CoqSn+GDNx4sRemiRXaUf2pEmTemcQoNeU+kBVVdXGjRvD/IYbbuipcaiTJ90AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSNPX1AL1t3rx5Yf61r30tzJ955pniGYMHDw7zgw8+OMzf9773hflRRx1VnGHkyJFh3tbWFuYNDQ3FM2Bn8vd///dhPmfOnDB/97vfHeal14Wqqqr99tuveE3k1VdfLV5z9913h/ktt9xS1wwAQNnSpUuL18yaNasXJqEneNINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkaeju7u7u6yF608yZM8P8+eefD/P3vOc9xTPOOuusMB87dmyYNzXF69MbGxuLMwA9q6OjI8yvv/76ML/mmmvC/LnnnivO8Na3vjXMjzjiiDAfOnRo8YzS61dbW1vxHgAA/A9PugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCQ73Z5uAAAA6C2edAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIElTXw8AQG0WLVoU5jfffHOY33333cUzHnnkkTBfsWJFmDc0NIT50KFDizPst99+YX7UUUeF+dvf/vbiGYcddliYt7W1Fe8BwI7pN7/5TZjfcccdYT5oUP5zy5EjRxav+bu/+7swnzFjRpiX3pMbGxuLM1AbT7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkDd3d3d19PQTAQPfiiy+G+Uc/+tHiPW6//fa6Zijt86yqqjr//PPD/IADDgjzzs7OMH/wwQeLM/zrv/5rmL/66qvFe5S0tLSE+ezZs8O8tPsUgP7rbW97W5hPnTo1zNevX188Y9iwYds102tt3bq1eM1zzz0X5n/605/C/Mtf/nKYn3POOcUZmpqaitfgSTcAAACkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkDd3d3d19PcSO5Etf+lLxmssuuyzMN2/e3FPj/M0aGhrCvL29vXiPf/mXfwnziy++eLtmeq1PfepTxWuuuOKKMO+JX+/GxsYwHzNmTJgvXbq07hno/77zne+E+YUXXhjmXV1ddc9w1VVXhfkFF1xQvEfptaE3rF69OswPPPDAMF+8eHHdM8yaNSvM3/KWt9R9BjuG0t/m+vXrw3zlypXFM5YtWxbm8+fPD/Nx48YVz5g0aVKY77LLLmHe1tYW5i0tLcUZSkrv2Zs2bSreY8OGDWH+4osvhvnDDz8c5q+88kpxhksvvbR4DX1r5syZYb777ruH+Xe/+93iGfvvv3+Yd3R0hPmKFSuKZ7S2tob5KaecEuZ33313XXlVVdXEiROL1+BJNwAAAKRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkKSprwfY0Rx77LHFa9auXRvmpV2627Zt266Z/hZHHXVUmJf2+lVVVZ1++uk9Nc5fVJqxqqrqJz/5SZiXdp/uueeexTPe/OY3h3ktc7Lju+yyy8L8s5/9bPoMpb2iH/nIR9Jn6A0jR44M89Lf/XHHHVf3DKtWrar7HgwMpd3RGzduDPNa9jovWrQozBcuXBjmjY2NxTPGjx8f5qXvs5T3hlpmKO0+7uzsDPPSv2VTk4/OO4OhQ4eG+ejRo4v3OOKII8K89Plx69atxTMeeuihMF+6dGmY77vvvmF+0003FWf45Cc/WbwGT7oBAAAgjdINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAklg1upze96U3Fa0o7Yq+55pow74k93aU9ktdee22YT506te4ZSkr7B3fdddfiPUp7FPfff/8w/9KXvlQ84/Wvf32Yt7S0FO9B//bggw8Wr+mNPdwlX/va1/p6hH7hDW94Q5iPGzeueI9ly5aFuT3d/B+lvc6lHdu//vWvi2e89NJLYb5gwYIwP/TQQ4tn7LnnnmE+ZsyYMO8Pe7pr+Xy0adOmuu7R2toa5u3t7cUZ6P/q/X3euHFj8Zrjjz8+zM8666wwr2XG9evXh/mVV14Z5u9+97vDfPbs2cUZqI0n3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJI09fUAA9Err7wS5hs2bEifYeLEiWE+fvz49BnWrl0b5tdee22YX3755cUzTjvttDC/+OKLw3yvvfYqntHY2Fi8hv6to6MjzN/1rnf10iR/3eTJk3vkmp1BQ0NDmJ9//vnFe1x66aVhPmLEiO2aif6pu7u77ms6OzvDfO7cuWF+7733FmeYN29emC9btizMR40aVTyj9Nmjq6ureI++Vnotr6ryZ4+tW7eG+dChQ8PcZ4KBofQ+0h/U8rs2derUMF+3bl2YDxs2LMxffvnl4gzUxpNuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgiT3dCebMmdPXI1RHH310mJd2/9Wy23T58uVh/sUvfjHMZ82aFeZf+cpXijPMnDkzzEv7Ntk5PPTQQ2G+cOHCXprkrzv55JP7eoQB45JLLile86UvfSnMm5q8PQ4EteyeLu1tXrNmTZgvWLAgzF988cXiDM3NzWF+4IEHhvm0adOKZ4wfPz7MhwwZEua98TdR+uxR2sFdVVX1wgsvhPngwYPDfMqUKWHe2tpanAF6S71/l6V95Rs3bqzr/vwPT7oBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkFpEmuOeee/p6hGrGjBlhXtrrV9o7WlVVdfrpp4d5abffzTffHOaHH354cYbSvnGoqqr6+c9/3tcjFE2dOrWvR9ip2MO9c6hlT/eWLVvCfOXKlWG+aNGiMF+4cGFxhtKe7QMOOKCuvKqqauzYsWFe2l9d2ufbG2rZ0/3MM8+E+cEHHxzme+yxR5iPHDmyOAM7vv7w+17LDIMG1ff8tPT1mzdvruv+/A9PugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCQWlW6nWnZ+3nfffakz1LK3b9KkSWH+q1/9KszPPffc4hnHHntsmF9xxRVhPmXKlDDvDzsSGRhmz57d1yMUjR8/vq9HgAGns7OzeM2KFSvCvLT3edmyZWHe3d1dnKH0fnjkkUeG+f777188o62tLczrfc+t5fPR1q1bw7y0M70WEydODPPSa+2QIUPCvLm5ebtnov+p5e9yR1Das13v92lPd8/xpBsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAECSpr4eYEezdu3a4jULFixInaG5ubl4zZVXXhnmDz/8cJgPHTq0eMa//du/hfnUqVOL94De8PLLL/f1CEVDhgzp6xFgwNm2bVvxmiVLloT5Y489FuaLFy8O84aGhuIMe+21V5gfffTRYT5x4sTiGS0tLcVr6tHV1VW8ZvPmzWG+cuXKuueYPHlymI8dOzbMW1tbw7ypyUfngaCWv8sdQWNjY5iXvs/S320tf9fUxpNuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgiWWD22nu3LnFa7Zs2ZI6w9atW4vX/OY3v6nrjFr2F952221hPmnSpDDP3hkK/0d3d3dfjwD0gVr2dL/88sth/sILL4R5aff0hAkTijOUrintlm5rayueUdrnW3qdLOWdnZ3FGdavXx/mr776api3t7cXzyj9W44cOTLMS3u4Bw3yvArYfl45AAAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJPZ0b6fHH3+8eE1pZ2e9Srs2q6q8T7OrqyvMN23aVDzjqquuCvOjjz46zI844ogwr2VXONRil112CfMlS5b00iR/XWl/LfD/V3qvq2VP96JFi8L8mWeeCfNRo0aF+SGHHFKcYeLEiWE+dOjQMG9ubi6eUe9+6dLnhlr2dJc+W5T2dJd2bFdVVe26665h3tLSEua1fMZix1d67dhRlL6PUl7L3y09w5NuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZr6eoD+prRE/o9//GPxHlu2bKlrhoaGhjA/++yzi/d4/vnnw3z27NnbNdNfMm/evDD/5je/Gebf+ta3wnzMmDHbPRP8JYcddliYP/XUU700yV+3cOHCvh4Bdjjbtm0L802bNhXv8corr4T58uXLw3yvvfYK8/333784w4QJE8K8paUlzBsbG4tnlD7fdHZ2hnnps83GjRuLM3R1dYX5iBEjwnzIkCHFMwYPHhzmtfxbMfCVPmvvKEp/U/V+n83NzXV9Pf/Dk24AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJPd2vUdozWcsu3dLOvJLhw4eH+Tve8Y7iPQYNiv8/pbTre926dcUzSt/nz372szA/5phjwvzDH/5wcYamJr/ClJ1wwglhft111/XSJH9df9gVvjO57777wvyggw4K81122aUnx+FvtHnz5jDfsGFD8R7r168P89J+6jFjxoT5IYccUpxh1113DfPSe3ppB3ctOjo6wry0z3zNmjXFM0qfb/bdd98wb2trK54xUPYv07d64m+qN2aot3OUtLS0pN5/Z+JJNwAAACRRugEAACCJ0g0AAABJlG4AAABIonQDAABAEqUbAAAAkijdAAAAkMSS49dYsWJFmC9evDh9htK+zr322qt4j9KO2Xe9611hfvXVVxfPqNcXv/jFMD/uuOOK96hl/ym87W1vC/MPfOADxXt0dnb21Dh/0axZs+qeobGxsafG2aEtWrSoeM3xxx8f5pdffnmYf+pTn9qekUjSE3u6S9eU/u5KO9v322+/4gwjR44M89Ke7lp29W7bti3MN23aFOZr164N89K+86oqf74p/TvUsoPbnm52Jtl7uocMGZJ6/52JJ90AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASe7pfo7TfdcmSJekz7LHHHmG+++67F+/R1BT/aL/+9a+H+ezZs4tn/PGPfyxeE1mzZk2Yn3feecV73HHHHWFe2p/KzmHEiBFh/vnPf754j0suuaSnxvmLVq5cWbzmoYceCvNjjjmmp8bZod14441136P0Okz/sGXLlrryqirv4S7tyC69vpR2U1dVVbW3txeviZR2bFdVVb3yyithXtp5XtrXW8v77bBhw8Lcjm16S3d3d1+PUFTLjBs2bAjzUh8onTF27NjiDNTGk24AAABIonQDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJ4o3pA1BnZ2eYP/nkk2G+YsWKnhznLxozZkyYDx8+vO4zRo8eHebf/va3i/c4/fTTw3zVqlXbNdNrPfroo8VrPvvZz4b5ZZddFualfwd2Dv/rf/2v4jV33nlnmM+ePbunxvmrzj///DCfM2dOmLe2tvbgNH1n3bp1YX7JJZfUfcYee+xR9z3It23btrryqqqqrq6uMG9sbAzzESNGhPmoUaOKM7S0tIR5d3d3mJf+Jqqqql566aXiNZGpU6eG+dixY4v3GDQoftbT0NCwXTPB36o3ftcWL14c5suXLw/ztWvXFs+4/fbbw3zvvfcO8/nz54f5/vvvX5yB2njSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJBlQe7p/97vfFa+56aabwvzWW28N882bN2/XTH+Lhx56KMxr2Sn88Y9/PMwnTJgQ5ocffnjdZ3z5y18O89Le0Vpcd911Yb506dIwP+mkk4pnvO997wvz0o5W+r/Sjtyqqqq77747zM8444wwv+eee7Zrpr/k2WefDfPS7+q1115bPKOtrW17RkqxcePGMH/7298e5q+++mrdM9Syc5i+1xM7skePHh3mQ4cODfPS7+vKlSuLM5T2V5feLzs7O4tn7LbbbmFe+tsfPnx4mJe+h6qyh5sdR+l39dBDDy3eY82aNWH+k5/8ZLtm+ku2bt0a5qW/+3vvvTfMS5+zqZ0n3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQJIBtaf7e9/7XvGa66+/Psxr2XWZbfHixWH+ne98p3iP9773vWG+5557hnlzc3PxjPe///1hfv/994f5f//3fxfPKOno6Ajz2267Lcw3bdpUPOMd73hHmNvTvXMYMmRImN95551h/oMf/CDMP/e5zxVnWL58eZjfcMMNYX7XXXcVz7jwwgvD/Nhjjw3z1tbWMP/9739fnOGyyy4L82XLloV5LbuAS69fe++9d/Ee9L329vYwr+X1ubTLe9iwYWG+efPmMC/93VZV+b2sdMauu+5aPGPChAlhXnqNa2qKPzLa081A0tjYGOZPPPFE8R5LliwJ8y1btoR56W+uqqrqDW94Q5iXXgOnTJkS5gcffHBxBmrjSTcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkDd3d3d19PQTAzm7btm3Fa5599tkwnzVrVpjfd999xTPmzZsX5kuWLAnzjRs3hvnYsWOLMxx99NFh/qY3vSnMzzzzzOIZtcxB/9fZ2Rnm69evL97jscceC/Pf//73YX7ggQeG+ZQpU4ozNDQ0hHnpo9rw4cOLZ4waNSrMW1tbw7w0YymH/qT0PnLPPfeE+dChQ3tynL+oJyra2WefHeaXXnppmNfyXulvvzaedAMAAEASpRsAAACSKN0AAACQROkGAACAJEo3AAAAJFG6AQAAIInSDQAAAEns6QYAdkiljzDbtm0r3mPTpk1hXtr13dTUVFfeE/dobGys+4xBg+p7DmNXL8Bf50k3AAAAJFG6AQAAIInSDQAAAEmUbgAAAEiidAMAAEASpRsAAACSKN0AAACQxJ5uAGBAquUjTldXV115Z2dnmHd0dBRnaG5uDvOWlpYwr3fHNgC5vEoDAABAEqUbAAAAkijdAAAAkETpBgAAgCRKNwAAACRRugEAACCJ0g0AAABJ7OkGAACAJJ50AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJIo3QAAAJBE6QYAAIAkSjcAAAAkUboBAAAgidINAAAASZRuAAAASKJ0AwAAQBKlGwAAAJL8P2ewwXqCo4HmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspecting the shapes of the training and testing feature sets\n",
        "print(f\"Shape of X_train_alt: {X_train_alt.shape}\")\n",
        "print(f\"Shape of X_test_alt: {X_test_alt.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx2NzUn16r6Y",
        "outputId": "8d585f9e-1890-4486-9bce-c528eabc0636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_alt: (219274, 28, 28, 1)\n",
            "Shape of X_test_alt: (54819, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network (CNN)**"
      ],
      "metadata": {
        "id": "GcaXIv3cMTji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the value to indicate grayscale image channels\n",
        "channels = 1  # Grayscale images only need a single channel\n",
        "\n",
        "# Reshape the feature datasets to include the channel dimension\n",
        "X_train_alt = X_train_alt.reshape((-1, 28, 28, channels))  # Using -1 is more generic than X_train_alt.shape[0]\n",
        "X_test_alt = X_test_alt.reshape((-1, 28, 28, channels))\n",
        "\n",
        "# Normalize the pixel values of images to the range [0, 1]\n",
        "X_train_alt = X_train_alt / 255.0  # Ensuring float division\n",
        "X_test_alt = X_test_alt / 255.0\n",
        "\n",
        "# Output the shapes of the processed datasets\n",
        "print(f'Train, Test shapes: {X_train_alt.shape}, {X_test_alt.shape}')\n"
      ],
      "metadata": {
        "id": "qwC1vu00_FTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b48e29-ebca-4f90-c8b2-2edc6b00d01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train, Test shapes: (219274, 28, 28, 1), (54819, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reshapes the training and testing datasets to include a channel dimension, indicating that the images are grayscale (hence, the channel size is 1). After reshaping, it normalizes the datasets by scaling the pixel values to the range [0, 1] for improved neural network performance. Finally, it prints the shapes of the modified datasets to confirm the changes."
      ],
      "metadata": {
        "id": "eZi6tQt4MXUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Architecture**"
      ],
      "metadata": {
        "id": "ZSUyeto9MfRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is a complete setup for constructing and summarizing a Convolutional Neural Network (CNN) model using the Keras API. This CNN, intended for image classification, consists of a stack of four convolutional blocks, each including a convolutional layer, batch normalization, a ReLU activation function, max pooling, and dropout for regularization. After the convolutional blocks, the architecture flattens the output and passes it through two dense layers, with the final layer using softmax activation for class probability output. The model is prepared for compilation and training, optimized for multi-class classification tasks, with architecture details outputted through the model summary."
      ],
      "metadata": {
        "id": "KeT6hM3-Mhfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Define image dimensions and number of classes\n",
        "Length, Height, RGB = 28, 28, 1  # Assuming these are previously defined\n",
        "NCl = 94  # Replace with actual number of classes\n",
        "\n",
        "# Building the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional block 1\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(Length, Height, RGB), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional block 2\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional block 3\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional block 4\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening and dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(350))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(NCl, activation='softmax'))  # Output layer with 'NCl' classes\n",
        "\n",
        "# Summarize the model architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "xzLfUt3m_Hl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7eb2372-2961-4d9a-da5d-46b42d744adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 14, 14, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 7, 7, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 3, 3, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 3, 3, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 3, 3, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 350)               89950     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 350)               1400      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 350)               0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 350)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 94)                32994     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 514104 (1.96 MB)\n",
            "Trainable params: 512444 (1.95 MB)\n",
            "Non-trainable params: 1660 (6.48 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of code is preparing the previously defined CNN model for training. It sets up the Adam optimizer with a learning rate of 0.01 and initializes an EarlyStopping callback to monitor the training loss, ceasing training if there hasn't been any improvement for five consecutive Epochs_. The model is compiled with categorical cross-entropy as the loss function, which is suitable for multi-class classification tasks, and accuracy as the metric to track during training."
      ],
      "metadata": {
        "id": "a6Ou9w0mMsup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming the CNN model 'model' is already defined.\n",
        "\n",
        "# Set the optimizer with a specified learning rate\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "\n",
        "# Set an early stopping callback to prevent overfitting\n",
        "early_stopping_callback = EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "# Specify the batch size and number of epochs for training\n",
        "Batch_ = 64\n",
        "Epochs_ = 5\n",
        "\n",
        "# Compile the model with the optimizer, loss function, and metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "wnIpLBRj_K71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code block, the optimizer, callback, batch size, and number of Epochs_ are defined for the training of the model. The Adam optimizer is used with a learning rate of 0.01, and early stopping is used to prevent overfitting. The batch size is set to 64, and the number of Epochs_ is set to 27. Finally, the model is compiled with categorical cross-entropy loss, the defined optimizer, and accuracy as a metric."
      ],
      "metadata": {
        "id": "nBmSEhIoMxc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data shapes and contents\n",
        "print(f\"X_train shape: {X_train_alt.shape}, y_train_alt shape: {y_train_alt.shape}\")\n",
        "print(f\"X_test shape: {X_test_alt.shape}, y_test_alt shape: {y_test_alt.shape}\")"
      ],
      "metadata": {
        "id": "pZxwj83R_Ndk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07e8d7e-827f-4dfb-ac4b-19f4207fd3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (219274, 28, 28, 1), y_train_alt shape: (219274, 94)\n",
            "X_test shape: (54819, 28, 28, 1), y_test_alt shape: (54819, 94)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, try fitting the model again\n",
        "history = model.fit(X_train_alt, y_train_alt, validation_data=(X_test_alt, y_test_alt), batch_size=batch_size, epochs=epochs, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEmRSmxrBLeB",
        "outputId": "0cc065ba-fbd4-4562-f262-6de2a21694da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3427/3427 [==============================] - 738s 214ms/step - loss: 0.6293 - accuracy: 0.8143 - val_loss: 0.2930 - val_accuracy: 0.9072\n",
            "Epoch 2/5\n",
            "3427/3427 [==============================] - 741s 216ms/step - loss: 0.3973 - accuracy: 0.8777 - val_loss: 0.3166 - val_accuracy: 0.8972\n",
            "Epoch 3/5\n",
            "3427/3427 [==============================] - 748s 218ms/step - loss: 0.3584 - accuracy: 0.8888 - val_loss: 0.2565 - val_accuracy: 0.9202\n",
            "Epoch 4/5\n",
            " 132/3427 [>.............................] - ETA: 10:53 - loss: 0.3444 - accuracy: 0.8937"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6uN7shAHBKwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating model accuracy on test data\n",
        "score = model.evaluate(X_test_alt,y_test_alt, batch_size = Batch_,verbose = 0)\n",
        "print(f\"Test Accuracy:{round(score[1],4)*100}%\")"
      ],
      "metadata": {
        "id": "lHeCFSYLCFq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prepared datasets, `X_train` and `y_train`, will be fed into the previously defined CNN model for training, adhering to a set batch size and epoch count. The code also includes a validation set, `X_test` and `y_test`, to monitor the model's performance during training. The progress and outcomes of the training sessions are captured in a `history` variable, which can be utilized for further evaluation and analysis."
      ],
      "metadata": {
        "id": "zFkAyB_1M3wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When evaluating the model against the test data, it achieved an accuracy of 92.53% and a loss of 0.2314. This suggests that the model correctly identified the labels for 92.53% of the test images, which is a relatively strong performance for a CNN with four layers."
      ],
      "metadata": {
        "id": "CjVIKvMZFuzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **MODEL PERFOMANCE PLOT**"
      ],
      "metadata": {
        "id": "I0yP1FGRPLQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot_history that visualizes the performance of a trained machine learning model over time. It produces two plots side by side: one for accuracy and the other for loss. Each plot shows lines for both the training set ('Train') and the validation set ('Validation'). This function helps in understanding how well the model is learning and generalizing to new data by providing a visual comparison between the training and validation metrics."
      ],
      "metadata": {
        "id": "6Wmc_c4HFoQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    # Create a figure with a specific size\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
        "\n",
        "    # Accuracy subplot\n",
        "    ax[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
        "    ax[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "    ax[0].set_title('Model Accuracy', fontsize=18)\n",
        "    ax[0].set_xlabel('Epoch', fontsize=14)\n",
        "    ax[0].set_ylabel('Accuracy', fontsize=14)\n",
        "    ax[0].legend(loc='upper left')\n",
        "    ax[0].grid(True)\n",
        "\n",
        "    # Loss subplot\n",
        "    ax[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
        "    ax[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
        "    ax[1].set_title('Model Loss', fontsize=18)\n",
        "    ax[1].set_xlabel('Epoch', fontsize=14)\n",
        "    ax[1].set_ylabel('Loss', fontsize=14)\n",
        "    ax[1].legend(loc='upper left')\n",
        "    ax[1].grid(True)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
        "    plt.show()\n",
        "\n",
        "# After training your model and obtaining the history object,\n",
        "#visualize the training and validation progress:\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "1rr01wwXNoz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function definition is for the \"Plott\" function. \"Data\" is the only argument accepted by the function. Two subplots are plotted in the figure: one plots model accuracy, and the other plots model loss. The \"data\" argument is then used to plot the accuracy and loss for training and validation, and the Matplotlib library is used to display the plot."
      ],
      "metadata": {
        "id": "O9H4bofLPW-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**"
      ],
      "metadata": {
        "id": "ZyZKjnV-PcM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up a figure with a 3x3 grid of subplots\n",
        "fig, axes = plt.subplots(3, 3, figsize=(8, 9))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Iterate through the flattened axes array and enumerate to get both index and axis\n",
        "for i, ax in enumerate(axes):\n",
        "    # Reshape the test image for display\n",
        "    img = np.reshape(X_test_alt[i], (28, 28))\n",
        "    ax.imshow(img, cmap=\"Greys\")\n",
        "\n",
        "    # Reshape the test image for model prediction\n",
        "    img_for_pred = img.reshape((1, 28, 28, 1))\n",
        "\n",
        "    # Predict the label for the reshaped test image\n",
        "    pred = model.predict(img_for_pred)\n",
        "    pred_label = label_dict_inv[np.argmax(pred)]\n",
        "\n",
        "    # Set the title of the subplot to the predicted label\n",
        "    ax.set_title(f\"Prediction: {pred_label}\")\n",
        "    ax.set_xticks([])  # Hide x-axis tick marks\n",
        "    ax.set_yticks([])  # Hide y-axis tick marks\n",
        "\n",
        "# Display the figure containing all subplots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-GJLxTGdOEXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code visualizes a subset of images from the test dataset `X_test_alt` and uses a trained model to predict the labels for these images. For each image in a 3x3 grid, it reshapes the data to a 28x28 format suitable for display, and then again reshapes it to (1, 28, 28, 1) for compatibility with the model's input requirements. The model then predicts the label for each reshaped image, and the prediction is displayed as a title on each subplot. Finally, a grid is added to each subplot."
      ],
      "metadata": {
        "id": "5b7N1_ifPhsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Takeaways**"
      ],
      "metadata": {
        "id": "Dz3hzOH8Plm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the Data**: In this phase, the MNIST dataset is imported and prepared for the model. Image data is scaled for uniformity and altered to ensure each image has only one color channel, catering to the grayscale nature of the images.\n",
        "\n",
        "**Building the CNN**: A CNN is crafted using Keras' Sequential API, comprising four layers that convolve the input to extract features, interspersed with dropout layers to prevent overfitting and max-pooling layers to reduce dimensionality. The architecture includes batch normalization for more stable training and ReLU activations to introduce non-linearity. The network concludes with a flattening step and a couple of dense layers, including a softmax output layer for multi-class probability distribution.\n",
        "\n",
        "**Model Training**: An Adam optimizer, along with a categorical cross-entropy loss function, drives the model's learning process over 5 epochs with mini-batches of 64 images each. The training session also validates the model's performance using a separate validation dataset, monitoring accuracy and loss.\n",
        "\n",
        "**Model Testing**: Post-training, the model undergoes an evaluation on a held-out test set to quantify its accuracy and determine how well it generalizes to new data.\n",
        "\n",
        "**Visual Assessment**: The training process is made transparent through visual aids. One function plots the training/validation accuracy and loss over epochs, and another function visualizes the model’s predictions by displaying images from the test set along with the predicted labels.\n",
        "\n",
        "Paraphrased Takeaway:\n",
        "\n",
        "**Data Setup**: The MNIST dataset is retrieved and processed, normalizing images and modifying their structure to be compatible with the grayscale format required by the model.\n",
        "\n",
        "**CNN Configuration**: Utilizing Keras, a CNN model is assembled with multiple layers for feature extraction, along with layers aimed at reducing overfitting and compressing the input. These include dropout, batch normalization, ReLU activations, and pooling layers, before the data stream is flattened and directed through dense layers ending with a softmax classifier.\n",
        "\n",
        "**Training Phase**: The model is put through its paces using the Adam optimization and categorical cross-entropy for loss measurement, training in batches and running for a series of epochs while tracking progress against validation data.\n",
        "\n",
        "**Testing the Model**: After training, the model's predictive accuracy is formally evaluated using test data.\n",
        "\n",
        "**Visualization Functions**: To provide insights into the model's learning trajectory and predictive capabilities, functions are created to graph the evolution of the model's accuracy and loss, and to exhibit the model's ability to predict characters, presenting the test images with their corresponding predicted classifications."
      ],
      "metadata": {
        "id": "QQQ9ouE4PoXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "e5WH-K6mP3fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, developing and training a CNN for the task of recognizing handwritten characters from the TMNIST dataset involves a systematic and structured process. The sequence of steps—ranging from data preparation and the establishment of the CNN architecture to the phases of training, evaluation, and graphical representation—culminates in a highly accurate and reliable character recognition system. In this particular project, the resulting model achieved a notable degree of accuracy, correctly classifying 92.53% of the handwritten characters and yielding a loss of 0.2314 when assessed against the test dataset. This level of performance is quite impressive, especially given the relatively simple 4-layer architecture of the CNN implemented."
      ],
      "metadata": {
        "id": "givfCLYqP77Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**"
      ],
      "metadata": {
        "id": "o42TwDOdQAir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.kaggle.com/code/huchunjun/99-1-tmnist-typefacemnist-chunjunhu\n",
        "2. https://www.youtube.com/watch?v=iqQgED9vV7k\n",
        "3. https://www.kaggle.com/code/sheshngupta/tminst-character-recognition-94-4-accuracy\n",
        "4. https://www.tensorflow.org/quantum/tutorials/mnist\n",
        "5. https://chat.openai.com/"
      ],
      "metadata": {
        "id": "kkoK4eFOQF3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) 2024 mihir-rahate\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n"
      ],
      "metadata": {
        "id": "xiN8ALfwQMk4"
      }
    }
  ]
}